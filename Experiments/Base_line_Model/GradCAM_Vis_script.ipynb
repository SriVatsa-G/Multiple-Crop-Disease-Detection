{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dfb98b9-0784-4ceb-958c-374160602c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 18:29:10.334295: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 18:29:10.493879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742821150.567643    6420 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742821150.583386    6420 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-24 18:29:10.718748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1742821157.434136    6420 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-03-24 18:29:27.066255: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:370] TFRecordDataset `buffer_size` is unspecified, default to 262144\n",
      "/home/srivatsa/.local/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: [['input_layer']]\n",
      "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
      "  warnings.warn(msg)\n",
      "I0000 00:00:1742821167.553859    6420 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: GradCAM_Crop_0.png & GradCAM_Disease_0.png\n",
      "Saved: GradCAM_Crop_1.png & GradCAM_Disease_1.png\n",
      "Saved: GradCAM_Crop_2.png & GradCAM_Disease_2.png\n",
      "Saved: GradCAM_Crop_3.png & GradCAM_Disease_3.png\n",
      "Saved: GradCAM_Crop_4.png & GradCAM_Disease_4.png\n",
      "Saved: GradCAM_Crop_5.png & GradCAM_Disease_5.png\n",
      "Saved: GradCAM_Crop_6.png & GradCAM_Disease_6.png\n",
      "Saved: GradCAM_Crop_7.png & GradCAM_Disease_7.png\n",
      "Saved: GradCAM_Crop_8.png & GradCAM_Disease_8.png\n",
      "Saved: GradCAM_Crop_9.png & GradCAM_Disease_9.png\n",
      "‚úÖ Grad-CAM Visualization Completed!\n",
      "‚úÖ Class mapping file saved at: /home/srivatsa/Multiple_Crop_Disease_Detection/reports/Baseline_Model/Plots/GradCAM//class_mapping.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 18:29:39.814102: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# üìå Grad-CAM Visualization Script for Baseline Multi-Task Model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# üìÅ Paths\n",
    "model_path = \"/home/srivatsa/Multiple_Crop_Disease_Detection/Models/Base_Line_Model/baseline_model_split.keras\"\n",
    "output_dir = \"/home/srivatsa/Multiple_Crop_Disease_Detection/reports/Baseline_Model/Plots/GradCAM/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# üìå Load Trained Model\n",
    "model = tf.keras.models.load_model(model_path,compile=False)\n",
    "\n",
    "# üìå Get Last Conv Layer\n",
    "last_conv_layer_name = \"top_conv\"  # EfficientNetV2B0 final conv block\n",
    "\n",
    "# üîç Grad-CAM Function\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None, output_name=\"crop_output\"):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.get_layer(output_name).output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# üìå Overlay Heatmap\n",
    "def overlay_heatmap(img, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
    "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), colormap)\n",
    "    overlayed = heatmap_color * alpha + img\n",
    "    return np.uint8(overlayed)\n",
    "\n",
    "# üìå Load Sample Images from Test TFRecord\n",
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"crop\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"disease\": tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed[\"image\"], channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, parsed[\"crop\"], parsed[\"disease\"]\n",
    "\n",
    "# üìÇ TFRecord\n",
    "test_tfrecord = \"/home/srivatsa/Multiple_Crop_Disease_Detection/Dataset/PlantVillage_Structured/AUG_TFRecord/split/test.tfrecord\"\n",
    "test_dataset = tf.data.TFRecordDataset(test_tfrecord).map(parse_example).batch(1)\n",
    "\n",
    "# üîç Visualize Grad-CAM for Few Samples\n",
    "num_samples = 10\n",
    "for i, (image, crop_label, disease_label) in enumerate(test_dataset.take(num_samples)):\n",
    "    img_np = image[0].numpy()\n",
    "    img_batch = tf.expand_dims(image[0], axis=0)\n",
    "\n",
    "    # Grad-CAM Heatmap (Disease)\n",
    "    heatmap_disease = make_gradcam_heatmap(img_batch, model, last_conv_layer_name, output_name=\"disease_output\")\n",
    "    overlay_disease = overlay_heatmap((img_np * 255).astype(np.uint8), heatmap_disease)\n",
    "\n",
    "    # Grad-CAM Heatmap (Crop)\n",
    "    heatmap_crop = make_gradcam_heatmap(img_batch, model, last_conv_layer_name, output_name=\"crop_output\")\n",
    "    overlay_crop = overlay_heatmap((img_np * 255).astype(np.uint8), heatmap_crop)\n",
    "\n",
    "    # üì∏ Save images\n",
    "    plt.imsave(f\"{output_dir}/GradCAM_Disease_{i}.png\", overlay_disease)\n",
    "    plt.imsave(f\"{output_dir}/GradCAM_Crop_{i}.png\", overlay_crop)\n",
    "\n",
    "    print(f\"Saved: GradCAM_Crop_{i}.png & GradCAM_Disease_{i}.png\")\n",
    "\n",
    "print(\"‚úÖ Grad-CAM Visualization Completed!\")\n",
    "\n",
    "# üìå Save Class Mapping\n",
    "crop_mapping = {0: \"Grape\", 1: \"Apple\", 2: \"Bell_Pepper\", 3: \"Corn\", 4: \"Strawberry\",\n",
    "                5: \"Tomato\", 6: \"Cherry\", 7: \"Peach\", 8: \"Potato\"}\n",
    "\n",
    "disease_mapping = {\n",
    "    0: \"Grape___Leaf_blight\", 1: \"Grape___Esca\", 2: \"Grape___Black_rot\", 3: \"Grape___healthy\",\n",
    "    4: \"Apple___Black_rot\", 5: \"Apple___Cedar_apple_rust\", 6: \"Apple___Apple_scab\", 7: \"Apple___healthy\",\n",
    "    8: \"Bell_Pepper___Bacterial_spot\", 9: \"Bell_Pepper___healthy\", 10: \"Corn___Common_rust\",\n",
    "    11: \"Corn___Cercospora_leaf_spot\", 12: \"Corn___Northern_Leaf_Blight\", 13: \"Corn___healthy\",\n",
    "    14: \"Strawberry___healthy\", 15: \"Strawberry___Leaf_scorch\", 16: \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "    17: \"Tomato___Bacterial_spot\", 18: \"Tomato___Target_Spot\", 19: \"Tomato___Leaf_Mold\",\n",
    "    20: \"Tomato___Septoria_leaf_spot\", 21: \"Tomato___Tomato_mosaic_virus\", 22: \"Tomato___healthy\",\n",
    "    23: \"Tomato___Early_blight\", 24: \"Tomato___Late_blight\", 25: \"Tomato___Spider_mites\",\n",
    "    26: \"Cherry___Powdery_mildew\", 27: \"Cherry___healthy\", 28: \"Peach___Bacterial_spot\",\n",
    "    29: \"Peach___healthy\", 30: \"Potato___healthy\", 31: \"Potato___Late_blight\", 32: \"Potato___Early_blight\"\n",
    "}\n",
    "\n",
    "with open(f\"{output_dir}/class_mapping.txt\", \"w\") as f:\n",
    "    f.write(\"üåø Crop Class Mapping:\\n\")\n",
    "    for k, v in crop_mapping.items():\n",
    "        f.write(f\"{k}: {v}\\n\")\n",
    "    f.write(\"\\nü¶† Disease Class Mapping:\\n\")\n",
    "    for k, v in disease_mapping.items():\n",
    "        f.write(f\"{k}: {v}\\n\")\n",
    "\n",
    "print(\"‚úÖ Class mapping file saved at:\", f\"{output_dir}/class_mapping.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
